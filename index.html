<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8" >
<meta name="description" content="Smoke100k: A Database for Smoke Detection">
<meta name="keywords" content="Smoke detection, object detection, deep learning">

<title>Smoke 100k: A Database for Smoke Detection</title>
<link href="css.css" rel="stylesheet" type="text/css" />
</head>

<body>

<center>
<h1>Smoke 100k: A Database for Smoke Detection</h2>
<h3>Hsiang-Yin Cheng, Jia-Li Yin, Bo-Hao Chen, and Zhi-Min Yu</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Department of Computer Science and Engineering, Yuan Ze University
College of Mathmatics and Computer Science, Fuzhou University
IEEE 8th Global Conference on Consumer Electronics (GCCE'19)
</p>

	
<p align="center" style="text-align:center"><span style="text-align:justify">
<IMG SRC="./figures/demo.jpg" ALT="results table"  style="width: auto; height: auto;max-width: 1200px;max-height: 450px; margin-left:35px;">
</span></p>
		
</center>
<h3 style="margin-left:35px;">Abstract</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Due to the complex scenarios and the limited feature
information in a single image, a precise smoke detection is
much more challenging in practice. Most of previous smoke
detection methods either extract textural and spatiotemporal
characteristics of smoke or separate the smoke and background
components of the image. However, those methods often fail
in detecting smoke positions because of the limited feature
information within a single image. Moreover, the task of smoke
detection can be better achieved if the extra information from
collected training dataset is available. One key issue is how to
build a training dataset of paired smoke images and groundtruth
bounding box positions for end-to-end learning. This paper
proposes a large-scale benchmark image dataset to train a smoke
detector. With the built dataset, experimental results demonstrate
that the discriminative models can be effectively trained as the
smoke detector to detect the smoldering fires precisely.
</p>

<!-- show img -->
<h3 style="margin-left:35px;">Details</h3>
<!--<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Test code in python: [<a href="./codes/python_iccv15.zip">Download</a>]
</p>-->

<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Our proposed smoke image dataset <b>Smoke 100k</b> consists of <b>100k</b> synthesized <b>smoke image,  smoke free image, smoke mask</b>, and <b>bounding box positions.</b></p>
</p>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
There are <b>3</b> subsets of synthesized smoke images for simulation of different smoldering fires. <b>3</b> subsets are detailed as follows:</p>
<ul style="text-align: justify; margin-left:35px; margin-right:35px;">
	<li><p><b>Smoke100k-L:</b> samples are synthesized by smoke masks
selected from the Low level with twenty kinds of angles, </p>
	</li>
	<li><p><b>Smoke100k-M:</b> samples are synthesized by smoke masks
selected from the Middle level with eight kinds of angles, </p>
	</li>
	<li><p><b>Smoke100k-H:</b> samples are synthesized by smoke masks
selected from the High level with fifteen kinds of angles.</p>
	</li>
</ul>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
For more details of the dataset, please refer to the paper <a href="https://ieeexplore.ieee.org/document/9015309">"Smoke 100k: A Database for Smoke Detection"</a>.

<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Amount of synthesized smoke image in each subset of smoke100k dataset are all increased to <b>40k</b> now.



<!-- show img -->
<h3 style="margin-left:35px;">Sample Smoke Images</h3>

<p align="center" style="text-align:center"><span style="text-align:justify">
<IMG SRC="./figures/demo.jpg" ALT="results table"  style="width: auto; height: auto;max-width: 1200px;max-height: 450px; margin-left:35px;">
</span></p>

<!--
<h4 style="margin-left:45px;">Super-resolved images from various datasets:</h4>

<ul style="margin-left:45px;">
	<h4>
  <li><a href="./html/SRdemoFrame_set5.html">Set 5</a>
  </li>
  <li><a href="./html/SRdemoFrame_set14.html">Set 14</a></li>
  <li><a href="./html/SRdemoFrame_BSD100.html">BSD 100</a></li>
	<h4>
</ul>
-->
	
<h3 style="margin-left:35px;">Download</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
 please download the dataset using Google Drive or Baidu Drive
</p>

<!--<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Reimplementation in Python: [<a href="https://github.com/bigmms/entropy-preserving-mapping-prior">GitHub</a>]
</p>-->

<h3 style="margin-left:35px;">Agreement</h3>
<!--<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Test code in python: [<a href="./codes/python_iccv15.zip">Download</a>]
</p>-->

<ul style="text-align: justify; margin-left:35px; margin-right:35px;">
	<li><p>The <b>Smoke100k dataset</b> is available for non-commercial research purposes only.</p>
	</li>
	<li><p>All images of the <b>Smoke100k dataset</b> are obtained from the LabelMe dataset [1], NYU dataset [2] which are not property of BigMMS group, Yuan Ze University. The BigMMS group is not responsible for the content nor the meaning of these images.</p>
	</li>
	<li><p>You agree not to reproduce, duplicate, copy, sell, trade, resell or exploit for any commercial purposes, any portion of the images and any portion of derived data.</p>
	</li>
	<li><p>You agree not to further copy, publish or distribute any portion of the <b>Smoke100k dataset</b>. Except, for internal use at a single site within the same organization it is allowed to make copies of the dataset.</p>
	</li>
	<li><p>The BigMMSLAB reserves the right to terminate your access to the <b>Smoke100k dataset</b> at any time.</p>
	</li>
	
</ul>


<h3 style="margin-left:35px;">Citation</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
H. Cheng, J. Yin, B. Chen and Z. Yu, <strong>Smoke 100k: A Database for Smoke Detection,</strong> 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), Osaka, Japan, 2019, pp. 596-597, doi: 10.1109/GCCE46687.2019.9015309.
[<a href="./iccv15.pdf">pdf</a>][<a href="./html/bib.html">bib</a>]
</p>

<h3 style="margin-left:35px;">References</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
[1] B. C. Russell, A. Torralba, K. P. Murphy, and W. T. Freeman, "Labelme: A database and web-based tool for image annotation," International Journal of Computer Vision, vol. 77, no. 1, pp. 157â€“173, May 2008.
</p>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
[2] P. K. Nathan Silberman, Derek Hoiem and R. Fergus, "Indoor segmentation and support inference from rgbd images," European Conference on Computer Vision (ECCV), 2012.
</p>
	
<!--<p style="text-align: justify; margin-left:35px; margin-right:35px;">
B. Chen, Y. Wu and L. Shi, <strong>"A Fast Image Contrast Enhancement Algorithm Using Entropy-Preserving Mapping Prior,"</strong> <i>IEEE Transactions on Circuits and Systems for Video Technology</i>, vol. 29, no. 1, pp. 38-49, Jan. 2019.
[<a href="https://ieeexplore.ieee.org/document/8107566">pdf</a>][<a href="./chen_tcsvt19_enhancement.html">bib</a>]
</p>-->

<!--<h3 style="margin-left:35px;">Related Work</h3>
<p style="text-align: justify; margin-left:35px; margin-right:35px;">
Ding Liu, Zhaowen Wang, Nasser Nasrabadi and Thomas S. Huang, <strong>Learning a Mixture of Deep Networks for Single Image Super-Resolution</strong>. <i>Asian Conference on Computer Vision</i>, 2016.
[<a href="../accv2016/index.html">project webpage</a>][<a href="../accv2016/accv2016_0395.pdf">pdf</a>][<a href="../accv2016/html/bib.html">bib</a>]
</p>-->
	
<style type="text/css">


body {
background-color: #F0F0FF;
background-color: #FFFFFF;
font: 1em Verdana;
border: 0px solid ;
line-height:150%;
}
</style>

</body>

</html>
